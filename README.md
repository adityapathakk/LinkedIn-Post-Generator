# LinkedIn Post Generator
Preface?<br>
Received this as a take-away project at the wrong time (super busy with a client demo at my current workplace), but I probably will keep expanding on this when I get time - as this finally got me to start learning and getting hands-on with fine-tuning! :)

## 🏛️ Architecture Design

The application consists of three core components:

### 1. SLM Preprocessor (fine-tuned T5-small)

- A custom Small Language Model fine-tuned from T5-small to refine raw user inputs (such as 'branding, college, talk') into polished LinkedIn post prompts.
- Adds structure, tone, and clarity markers based on minimalistic inputs.
- Do note that while the application accepts ideas, big or small, the preprocessor currently works best with comma-separated concepts, like mentioned in the 'AI Intern Task' Google Doc. 

### 2. LLM Generator (Llama 3.2-3B via Ollama)

- An open-source, powerful Large Language Model that takes refined prompts from the SLM to generate professional LinkedIn posts.
- Enhanced with detailed instructions and career-specific contexts to ensure relevance and engagement.
- Do note that there's currently no GPU support, so generating posts can take some time. 

### 3. User Interface (Streamlit)

- Provides a friendly, intuitive interface for users to input ideas and select their profession.
- Displays generated LinkedIn posts with historical record-keeping of previously generated content.
- Do note that the posts are currently stored in the `session_state` variable of Streamlit, as no database is implemented for actual record-keeping.

## ⚙️ SLM Logic and Role

The SLM's main task is prompt preprocessing:

- Converts raw user input (typically brief, keyword-based) into a more structured, LinkedIn-friendly prompt.
- Adds clarity, emotion, structure, and stylistic elements (such as emojis or professional tone).
- Trained using synthetic data generated by leveraging the CommonGen dataset augmented with professional templates and formats (see `slm-finetuning.ipynb`).

## 📚 Training Datasets Used

The primary dataset used:

- Synthetic Dataset from CommonGen:
-   Raw concept sets (e.g., "branding, talk, college") paired with refined, professionally templated sentences.
-   Included augmented template pairs to introduce diversity and robustness to the model.

## 🧪 Test Cases

### Test Case 1: Short Keyword-based Input

#### Raw Input:
(branding, talk, college)

#### SLM Output:
"Had the honour of delivering a talk on branding at college 🎓 – here's what I learned:"

#### LLM Output (No Persona):

Had the honour of delivering a talk on branding at college 🎓
Branding isn’t just logos and colors—it’s identity, personality, and communication wrapped into one cohesive package. During my session, I emphasized the importance of authenticity and consistency in branding.
One key takeaway? Your brand is how people feel about your business. Ensuring this feeling aligns with your values and actions is crucial. 💡

How do you ensure your personal or professional branding resonates authentically?
Let's continue building brands that speak volumes!
#Branding #MarketingStrategy #PersonalBranding #CollegeTalk #Authenticity

### Test Case 2: Single Sentence Input

#### Raw Input:
"I recently gave a talk about generative AI at my university!"

#### SLM Output:
"Excited to have recently shared insights about Generative AI at my university! 🚀 Here are some highlights:"

#### LLM Output (With Persona: AI Expert):

Excited to have recently shared insights about Generative AI at my university! 🚀
Generative AI isn't just technology; it's reshaping creativity, productivity, and even ethics in profound ways. During my talk, we delved into both the promising advancements and the important ethical considerations around its usage.
The energy in the room was fantastic, and it sparked thoughtful discussions around bias, creativity, and human-AI collaboration. 🤖

How do you see Generative AI impacting your field?
Let's continue innovating responsibly!
#GenerativeAI #MachineLearning #EthicalAI #Innovation #FutureOfAI

### Test Case 3: Three-Sentence Input (Bypassing SLM)

#### Raw Input:
"I gave a talk at a local startup event about effective branding. The audience was very engaged. Received great feedback!"

#### SLM Output:
Bypassed due to input length exceeding one sentence.

#### LLM Output (No Persona):
I gave a talk at a local startup event about effective branding. The audience was very engaged. Received great feedback!
Branding is often underestimated, yet it's a critical factor in setting startups apart. I shared practical strategies, real-world examples, and emphasized authenticity and clarity.
Engagement from the audience was inspiring, reflecting the hunger entrepreneurs have for knowledge that drives growth and success.

What branding strategies have significantly impacted your business or professional journey?
Here's to continued growth and impactful branding!
#Branding #StartupEvent #Entrepreneurship #ProfessionalGrowth #BusinessInsights

## Future Scope

- more robust SLM, which can handle and refine different types of ideas
- post-processor SLM
- experimenting with other LLMs
- returning 3 different posts, letting the user choose which one they like
- separate UI space to input previous posts for added context (or maybe even use some LinkedIn API/create a custom web-parsing solution if API doesn't exist, to return previous posts automatically, given the username)
- and more...
